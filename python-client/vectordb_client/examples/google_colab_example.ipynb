{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/rdmurugan/d-vecDB/blob/master/python-client/vectordb_client/examples/google_colab_example.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# d-vecDB Python Client - Google Colab Example\n",
    "\n",
    "This notebook demonstrates how to use the d-vecDB Python client in Google Colab for vector similarity search and embeddings management.\n",
    "\n",
    "## What you'll learn:\n",
    "- How to install and set up d-vecDB client in Colab\n",
    "- Connect to a remote d-vecDB server\n",
    "- Create collections and insert vectors\n",
    "- Perform similarity searches\n",
    "- Work with text embeddings using sentence transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "installation"
   },
   "source": [
    "## üîß Installation\n",
    "\n",
    "First, let's install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-packages"
   },
   "outputs": [],
   "source": [
    "# Install the d-vecDB Python client and dependencies\n",
    "!pip install vectordb-client sentence-transformers numpy pandas matplotlib\n",
    "\n",
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Any\n",
    "import json\n",
    "import time\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "print(\"‚úÖ Installation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-client"
   },
   "source": [
    "## üöÄ Setting up the VectorDB Client\n",
    "\n",
    "**Note**: For this example, you'll need access to a running d-vecDB server. You can:\n",
    "1. Run a local server and use ngrok to expose it\n",
    "2. Use a cloud-hosted d-vecDB instance\n",
    "3. For demo purposes, we'll show how to set up the client (you'll need to replace with your actual server details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup-client-code"
   },
   "outputs": [],
   "source": [
    "from vectordb_client import VectorDBClient\n",
    "from vectordb_client.types import (\n",
    "    CollectionConfig, Vector, DistanceMetric, \n",
    "    IndexConfig, VectorType\n",
    ")\n",
    "\n",
    "# Configuration - Replace with your server details\n",
    "SERVER_HOST = \"your-server-host.com\"  # Replace with your server host\n",
    "SERVER_PORT = 8080  # Replace with your server port\n",
    "\n",
    "# For local development with ngrok, it might look like:\n",
    "# SERVER_HOST = \"abc123.ngrok.io\"\n",
    "# SERVER_PORT = 80\n",
    "\n",
    "print(f\"üîå Connecting to d-vecDB server at {SERVER_HOST}:{SERVER_PORT}...\")\n",
    "\n",
    "try:\n",
    "    # Initialize the client\n",
    "    client = VectorDBClient(host=SERVER_HOST, port=SERVER_PORT)\n",
    "    \n",
    "    # Test the connection\n",
    "    if client.ping():\n",
    "        print(\"‚úÖ Successfully connected to d-vecDB!\")\n",
    "        \n",
    "        # Get server info\n",
    "        server_info = client.get_server_info()\n",
    "        print(f\"üìä Server Info: {server_info}\")\n",
    "    else:\n",
    "        print(\"‚ùå Could not connect to d-vecDB server\")\n",
    "        print(\"Please check your server configuration and try again.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Connection failed: {e}\")\n",
    "    print(\"\\nüí° To run this example, you need:\")\n",
    "    print(\"1. A running d-vecDB server\")\n",
    "    print(\"2. Update SERVER_HOST and SERVER_PORT above\")\n",
    "    print(\"3. Ensure the server is accessible from Colab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sample-data"
   },
   "source": [
    "## üìÑ Preparing Sample Data\n",
    "\n",
    "Let's create some sample documents and generate embeddings for them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sample-data-code"
   },
   "outputs": [],
   "source": [
    "# Sample documents for demonstration\n",
    "sample_documents = [\n",
    "    \"The quick brown fox jumps over the lazy dog\",\n",
    "    \"Machine learning is a subset of artificial intelligence\",\n",
    "    \"Vector databases enable efficient similarity search\",\n",
    "    \"Python is a popular programming language for data science\",\n",
    "    \"Natural language processing helps computers understand text\",\n",
    "    \"Deep learning models can generate realistic images\",\n",
    "    \"Cloud computing provides scalable infrastructure solutions\",\n",
    "    \"Database optimization improves query performance\",\n",
    "    \"Artificial neural networks mimic biological brain functions\",\n",
    "    \"Big data analytics reveals insights from large datasets\"\n",
    "]\n",
    "\n",
    "print(f\"üìö Sample documents ({len(sample_documents)} total):\")\n",
    "for i, doc in enumerate(sample_documents, 1):\n",
    "    print(f\"{i:2d}. {doc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "embeddings"
   },
   "source": [
    "## üî§ Generating Text Embeddings\n",
    "\n",
    "We'll use sentence-transformers to convert our text documents into vector embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "embeddings-code"
   },
   "outputs": [],
   "source": [
    "# Initialize the sentence transformer model\n",
    "print(\"ü§ñ Loading sentence transformer model...\")\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # Lightweight model, good for Colab\n",
    "\n",
    "# Generate embeddings\n",
    "print(\"‚ö° Generating embeddings...\")\n",
    "embeddings = model.encode(sample_documents)\n",
    "\n",
    "print(f\"‚úÖ Generated {len(embeddings)} embeddings\")\n",
    "print(f\"üìè Embedding dimension: {embeddings.shape[1]}\")\n",
    "print(f\"üî¢ Data type: {embeddings.dtype}\")\n",
    "\n",
    "# Convert to list format for d-vecDB\n",
    "embedding_vectors = [embedding.tolist() for embedding in embeddings]\n",
    "\n",
    "print(f\"\\nüìä First embedding preview (first 10 dimensions):\")\n",
    "print(embedding_vectors[0][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualization"
   },
   "source": [
    "## üìà Visualizing Embeddings\n",
    "\n",
    "Let's visualize our embeddings in 2D using PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "visualization-code"
   },
   "outputs": [],
   "source": [
    "# Reduce embeddings to 2D for visualization\n",
    "pca = PCA(n_components=2)\n",
    "embeddings_2d = pca.fit_transform(embeddings)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], \n",
    "                     alpha=0.7, s=100, c=range(len(sample_documents)), \n",
    "                     cmap='tab10')\n",
    "\n",
    "# Add labels for each point\n",
    "for i, doc in enumerate(sample_documents):\n",
    "    plt.annotate(f\"{i+1}\", \n",
    "                xy=(embeddings_2d[i, 0], embeddings_2d[i, 1]),\n",
    "                xytext=(5, 5), textcoords='offset points',\n",
    "                fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.title('Document Embeddings Visualization (PCA)', fontsize=16)\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)', fontsize=12)\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìã Document Reference:\")\n",
    "for i, doc in enumerate(sample_documents, 1):\n",
    "    print(f\"{i:2d}. {doc[:50]}{'...' if len(doc) > 50 else ''}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create-collection"
   },
   "source": [
    "## üìÅ Creating a Collection\n",
    "\n",
    "Now let's create a collection in d-vecDB to store our embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create-collection-code"
   },
   "outputs": [],
   "source": [
    "# Collection configuration\n",
    "collection_name = \"colab_text_embeddings\"\n",
    "embedding_dimension = len(embedding_vectors[0])\n",
    "\n",
    "print(f\"üìÅ Creating collection '{collection_name}'...\")\n",
    "\n",
    "try:\n",
    "    # Clean up any existing collection\n",
    "    try:\n",
    "        client.delete_collection(collection_name)\n",
    "        print(f\"üóëÔ∏è  Deleted existing collection\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Create new collection with cosine similarity\n",
    "    response = client.create_collection_simple(\n",
    "        name=collection_name,\n",
    "        dimension=embedding_dimension,\n",
    "        distance_metric=DistanceMetric.COSINE\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Created collection: {response}\")\n",
    "    \n",
    "    # List all collections to verify\n",
    "    collections = client.list_collections()\n",
    "    print(f\"üìã Available collections: {collections}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to create collection: {e}\")\n",
    "    print(\"Please ensure your d-vecDB server is running and accessible.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "insert-vectors"
   },
   "source": [
    "## ‚¨ÜÔ∏è Inserting Vectors\n",
    "\n",
    "Let's insert our document embeddings into the collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "insert-vectors-code"
   },
   "outputs": [],
   "source": [
    "print(\"‚¨ÜÔ∏è  Inserting vectors into collection...\")\n",
    "\n",
    "try:\n",
    "    # Prepare vectors with metadata\n",
    "    vectors_to_insert = []\n",
    "    \n",
    "    for i, (doc, embedding) in enumerate(zip(sample_documents, embedding_vectors)):\n",
    "        vector = Vector(\n",
    "            id=str(i + 1),\n",
    "            values=embedding,\n",
    "            metadata={\n",
    "                \"document\": doc,\n",
    "                \"length\": len(doc),\n",
    "                \"index\": i + 1,\n",
    "                \"word_count\": len(doc.split())\n",
    "            }\n",
    "        )\n",
    "        vectors_to_insert.append(vector)\n",
    "    \n",
    "    # Insert vectors in batch\n",
    "    start_time = time.time()\n",
    "    response = client.upsert_vectors(collection_name, vectors_to_insert)\n",
    "    insert_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"‚úÖ Inserted {len(vectors_to_insert)} vectors in {insert_time:.2f} seconds\")\n",
    "    print(f\"üìä Insert response: {response}\")\n",
    "    \n",
    "    # Get collection statistics\n",
    "    try:\n",
    "        stats = client.get_collection_stats(collection_name)\n",
    "        print(f\"üìà Collection stats: {stats}\")\n",
    "    except:\n",
    "        print(\"‚ÑπÔ∏è  Collection stats not available\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to insert vectors: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "similarity-search"
   },
   "source": [
    "## üîç Similarity Search\n",
    "\n",
    "Now let's perform similarity searches to find related documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "similarity-search-code"
   },
   "outputs": [],
   "source": [
    "def search_similar_documents(query_text: str, top_k: int = 5):\n",
    "    \"\"\"Search for documents similar to the query text.\"\"\"\n",
    "    print(f\"\\nüîç Searching for: '{query_text}'\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        # Generate embedding for query\n",
    "        query_embedding = model.encode([query_text])[0].tolist()\n",
    "        \n",
    "        # Perform search\n",
    "        start_time = time.time()\n",
    "        results = client.search_vectors(\n",
    "            collection_name=collection_name,\n",
    "            query_vector=query_embedding,\n",
    "            top_k=top_k\n",
    "        )\n",
    "        search_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"‚ö° Search completed in {search_time:.3f} seconds\")\n",
    "        print(f\"üìã Found {len(results)} results:\\n\")\n",
    "        \n",
    "        for i, result in enumerate(results, 1):\n",
    "            doc_text = result.metadata.get('document', 'N/A')\n",
    "            similarity = 1 - result.score  # Convert distance to similarity for cosine\n",
    "            \n",
    "            print(f\"{i}. [Similarity: {similarity:.3f}] {doc_text}\")\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Search failed: {e}\")\n",
    "        return []\n",
    "\n",
    "# Example searches\n",
    "search_queries = [\n",
    "    \"artificial intelligence and machine learning\",\n",
    "    \"database and data storage\",\n",
    "    \"programming languages for data\",\n",
    "    \"computer vision and image processing\"\n",
    "]\n",
    "\n",
    "for query in search_queries:\n",
    "    search_similar_documents(query, top_k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "interactive-search"
   },
   "source": [
    "## üéØ Interactive Search\n",
    "\n",
    "Try your own search queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "interactive-search-code"
   },
   "outputs": [],
   "source": [
    "# Interactive search - modify this cell to try different queries\n",
    "your_query = \"neural networks and AI\"  # ‚Üê Change this to your query\n",
    "\n",
    "print(\"üéØ Your custom search:\")\n",
    "results = search_similar_documents(your_query, top_k=5)\n",
    "\n",
    "# Show detailed results with metadata\n",
    "if results:\n",
    "    print(\"\\nüìä Detailed Results:\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for i, result in enumerate(results, 1):\n",
    "        similarity = 1 - result.score\n",
    "        metadata = result.metadata\n",
    "        \n",
    "        print(f\"\\nResult {i}:\")\n",
    "        print(f\"  üìÑ Document: {metadata.get('document', 'N/A')}\")\n",
    "        print(f\"  üéØ Similarity: {similarity:.4f}\")\n",
    "        print(f\"  üìè Length: {metadata.get('length', 'N/A')} characters\")\n",
    "        print(f\"  üí¨ Words: {metadata.get('word_count', 'N/A')}\")\n",
    "        print(f\"  üÜî ID: {result.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vector-operations"
   },
   "source": [
    "## üîß Advanced Vector Operations\n",
    "\n",
    "Let's explore some advanced operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vector-operations-code"
   },
   "outputs": [],
   "source": [
    "print(\"üîß Advanced Vector Operations\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "try:\n",
    "    # 1. Get a specific vector\n",
    "    print(\"\\n1Ô∏è‚É£ Retrieving specific vector...\")\n",
    "    vector_id = \"1\"\n",
    "    retrieved_vector = client.get_vector(collection_name, vector_id)\n",
    "    if retrieved_vector:\n",
    "        print(f\"‚úÖ Retrieved vector {vector_id}:\")\n",
    "        print(f\"   Document: {retrieved_vector.metadata.get('document', 'N/A')[:50]}...\")\n",
    "        print(f\"   Dimension: {len(retrieved_vector.values)}\")\n",
    "    \n",
    "    # 2. Filter search with metadata\n",
    "    print(\"\\n2Ô∏è‚É£ Filtered search (documents with >50 characters)...\")\n",
    "    query_text = \"data science programming\"\n",
    "    query_embedding = model.encode([query_text])[0].tolist()\n",
    "    \n",
    "    # Note: Metadata filtering syntax depends on your d-vecDB server implementation\n",
    "    # This is a conceptual example - adjust based on your server's API\n",
    "    filtered_results = client.search_vectors(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=query_embedding,\n",
    "        top_k=5\n",
    "        # filter={\"length\": {\"$gt\": 50}}  # Uncomment if your server supports filtering\n",
    "    )\n",
    "    \n",
    "    print(f\"üìã Filtered results: {len(filtered_results)}\")\n",
    "    for result in filtered_results[:3]:\n",
    "        doc_length = result.metadata.get('length', 0)\n",
    "        if doc_length > 50:  # Client-side filtering as example\n",
    "            similarity = 1 - result.score\n",
    "            print(f\"   ‚Ä¢ [Similarity: {similarity:.3f}, Length: {doc_length}] {result.metadata.get('document', 'N/A')[:60]}...\")\n",
    "    \n",
    "    # 3. Batch operations\n",
    "    print(\"\\n3Ô∏è‚É£ Batch vector retrieval...\")\n",
    "    vector_ids = [\"1\", \"3\", \"5\"]\n",
    "    batch_vectors = client.get_vectors(collection_name, vector_ids)\n",
    "    print(f\"‚úÖ Retrieved {len(batch_vectors)} vectors in batch\")\n",
    "    \n",
    "    for vector in batch_vectors:\n",
    "        doc = vector.metadata.get('document', 'N/A')\n",
    "        print(f\"   ‚Ä¢ ID {vector.id}: {doc[:40]}...\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Advanced operations failed: {e}\")\n",
    "    print(\"Some operations may not be supported by your d-vecDB server version.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "performance-test"
   },
   "source": [
    "## ‚ö° Performance Testing\n",
    "\n",
    "Let's test the performance of our vector database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "performance-test-code"
   },
   "outputs": [],
   "source": [
    "print(\"‚ö° Performance Testing\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "try:\n",
    "    # Test search performance\n",
    "    test_queries = [\n",
    "        \"machine learning algorithms\",\n",
    "        \"database optimization techniques\", \n",
    "        \"natural language processing\",\n",
    "        \"cloud computing infrastructure\",\n",
    "        \"artificial intelligence applications\"\n",
    "    ]\n",
    "    \n",
    "    search_times = []\n",
    "    \n",
    "    print(\"üîç Running search performance test...\")\n",
    "    for i, query in enumerate(test_queries, 1):\n",
    "        query_embedding = model.encode([query])[0].tolist()\n",
    "        \n",
    "        start_time = time.time()\n",
    "        results = client.search_vectors(\n",
    "            collection_name=collection_name,\n",
    "            query_vector=query_embedding,\n",
    "            top_k=5\n",
    "        )\n",
    "        search_time = (time.time() - start_time) * 1000  # Convert to milliseconds\n",
    "        search_times.append(search_time)\n",
    "        \n",
    "        print(f\"   Query {i}: {search_time:.2f}ms ({len(results)} results)\")\n",
    "    \n",
    "    # Performance statistics\n",
    "    avg_time = np.mean(search_times)\n",
    "    min_time = np.min(search_times)\n",
    "    max_time = np.max(search_times)\n",
    "    \n",
    "    print(f\"\\nüìä Performance Summary:\")\n",
    "    print(f\"   Average search time: {avg_time:.2f}ms\")\n",
    "    print(f\"   Fastest search: {min_time:.2f}ms\")\n",
    "    print(f\"   Slowest search: {max_time:.2f}ms\")\n",
    "    \n",
    "    # Visualize performance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(range(1, len(search_times) + 1), search_times, alpha=0.7)\n",
    "    plt.axhline(y=avg_time, color='r', linestyle='--', label=f'Average: {avg_time:.2f}ms')\n",
    "    plt.xlabel('Query Number')\n",
    "    plt.ylabel('Search Time (milliseconds)')\n",
    "    plt.title('Vector Search Performance')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Performance test failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cleanup"
   },
   "source": [
    "## üßπ Cleanup\n",
    "\n",
    "Clean up resources when done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cleanup-code"
   },
   "outputs": [],
   "source": [
    "print(\"üßπ Cleaning up resources...\")\n",
    "\n",
    "try:\n",
    "    # Optionally delete the collection\n",
    "    delete_collection = False  # Set to True if you want to clean up\n",
    "    \n",
    "    if delete_collection:\n",
    "        response = client.delete_collection(collection_name)\n",
    "        print(f\"üóëÔ∏è  Deleted collection '{collection_name}': {response}\")\n",
    "    else:\n",
    "        print(f\"‚ÑπÔ∏è  Collection '{collection_name}' preserved for further use\")\n",
    "    \n",
    "    # List remaining collections\n",
    "    collections = client.list_collections()\n",
    "    print(f\"üìã Remaining collections: {collections}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Cleanup failed: {e}\")\n",
    "\n",
    "print(\"\\n‚úÖ Notebook execution completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "next-steps"
   },
   "source": [
    "## üöÄ Next Steps\n",
    "\n",
    "Congratulations! You've successfully:\n",
    "- ‚úÖ Set up d-vecDB client in Google Colab\n",
    "- ‚úÖ Generated text embeddings using sentence transformers\n",
    "- ‚úÖ Created a vector collection\n",
    "- ‚úÖ Inserted and searched vectors\n",
    "- ‚úÖ Performed similarity searches\n",
    "- ‚úÖ Tested performance\n",
    "\n",
    "### What to try next:\n",
    "\n",
    "1. **Scale up**: Try with larger datasets (1000+ documents)\n",
    "2. **Different embeddings**: Experiment with different sentence transformer models\n",
    "3. **Real data**: Use your own documents or datasets\n",
    "4. **Advanced features**: Explore filtering, metadata queries, and batch operations\n",
    "5. **Integration**: Connect with your applications or data pipelines\n",
    "\n",
    "### Useful Resources:\n",
    "\n",
    "- üìö [d-vecDB Documentation](https://github.com/rdmurugan/d-vecDB)\n",
    "- ü§ó [Sentence Transformers](https://www.sbert.net/)\n",
    "- üêç [Python Client API Reference](https://github.com/rdmurugan/d-vecDB/tree/master/python-client)\n",
    "\n",
    "### Need Help?\n",
    "\n",
    "- üêõ Report issues: [GitHub Issues](https://github.com/rdmurugan/d-vecDB/issues)\n",
    "- üí¨ Discussions: [GitHub Discussions](https://github.com/rdmurugan/d-vecDB/discussions)\n",
    "\n",
    "Happy vector searching! üéâ"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}